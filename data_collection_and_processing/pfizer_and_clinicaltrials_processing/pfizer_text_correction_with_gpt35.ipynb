{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Processing with GPT-3.5 for Pfizer Documents\n",
    "\n",
    "This notebook leverages the GPT-3.5 model to correct writing errors in Pfizer text documents. The goal is to enhance the text's grammatical correctness without altering the original wording. The process involves importing necessary libraries, setting up the OpenAI API, and processing the text through the GPT-3.5 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up the OpenAI API\n",
    "\n",
    "Next, we configure the OpenAI API to interact with the GPT-3.5 model. The API key, base URL, type, version, and deployment name are retrieved from environment variables to ensure secure and flexible configuration.\n",
    "\n",
    "- **API Key**: Authenticates requests to the OpenAI API.\n",
    "- **API Base**: Specifies the base URL for the API.\n",
    "- **API Type**: Indicates the type of OpenAI API being used (Azure in this case).\n",
    "- **API Version**: Specifies the version of the OpenAI API.\n",
    "- **Deployment Name**: Identifies the specific deployment of the GPT-3.5 model.\n",
    "\n",
    "Using environment variables helps to keep sensitive information secure and allows for easy updates and configuration changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY_GPT_35\")\n",
    "openai.api_base = os.getenv(\"OPENAI_API_BASE_GPT_35\")\n",
    "openai.api_type = 'azure'\n",
    "openai.api_version = '2023-05-15'\n",
    "openai.deployment_name = os.getenv(\"OPENAI_DEPLOYMENT_NAME_GPT_35_16k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Text Files\n",
    "\n",
    "In this step, we load the text files from the specified directory. Each text file contains a fragment of Pfizer documents that need grammatical corrections. We read the content of each file and store it in a list for further processing.\n",
    "\n",
    "- **Directory**: The text files are located in the `fragments/first_section` and `fragments/second_section` directory.\n",
    "- **File Reading**: We iterate through all files in the directory, read the content of each text file, and store the content in a list. The names of the files are also stored (excluding the `.txt` extension) for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store the texts and file names\n",
    "texts = []\n",
    "names = []\n",
    "\n",
    "# Iterate through all files in the specified directory\n",
    "for file in os.listdir(\"fragments/second_section\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        # Open and read the content of each text file\n",
    "        with open(os.path.join(\"fragments/second_section\", file), \"r\", encoding=\"utf-8\") as f:\n",
    "            texts.append(f.read())\n",
    "            names.append(file[:-4])  # Store the file name without the .txt extension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correcting Text with GPT-3.5\n",
    "\n",
    "In this section, we use the GPT-3.5 model to correct writing errors in the loaded text fragments. The model corrects typos, misspelled words, strange characters, and improper spacing without changing the original wording or sentence structure. If a text fragment is empty or too short (less than 250 words), it is skipped to ensure meaningful corrections.\n",
    "\n",
    "For each text fragment:\n",
    "- **Text Verification**: Check if the text is non-empty and has at least 250 words.\n",
    "- **Prompt Preparation**: Create a prompt instructing the GPT-3.5 model to correct errors while preserving the original words and sentences.\n",
    "- **Model Interaction**: Send the prompt to the GPT-3.5 model and receive the corrected text.\n",
    "- **Saving Results**: Save the corrected text to a new file in the `fragments/second_section_corrected` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NCT00935012 is empty or too short\n",
      "NCT00935012 is empty or too short\n",
      "NCT00935012 is empty or too short\n",
      "NCT00935012 is empty or too short\n",
      "NCT00935012 is empty or too short\n",
      "NCT00935012 is empty or too short\n",
      "NCT00935012 is empty or too short\n",
      "NCT00935012 is empty or too short\n",
      "NCT00935012 is empty or too short\n",
      "NCT00935012 is empty or too short\n",
      "NCT00935012 is empty or too short\n",
      "NCT00935012 is empty or too short\n",
      "NCT00935012 is empty or too short\n",
      "NCT00935012 is empty or too short\n",
      "NCT00935012 is empty or too short\n"
     ]
    }
   ],
   "source": [
    "# Iterate through each text in the texts list\n",
    "for text in texts:\n",
    "    # Check if the text is empty or too short\n",
    "    if text == \"\" or len(text.split()) < 250:\n",
    "        print(names[texts.index(text)], \"is empty or too short\")\n",
    "        continue\n",
    "\n",
    "    # Prepare the prompt for the GPT-3.5 model\n",
    "    prompt = \"\"\"The following text in triple backticks is a fragment of a medical text. This text could have some words or sentences separated, misspelled words, typos or strange characters. Correct the text without changing any of the words or sentences. If you find some vignettes put \\\"-\\\" between them. If you find some strange characters, delete them. If you find some misspelled words, correct them. If you find some words or sentences separated, join them. If you find some words or sentences joined, separate them. Return just the text with the corrections.\n",
    "    Text: ```{text}```\n",
    "    \"\"\"\n",
    "    \n",
    "    # Interact with the GPT-3.5 model to get the corrected text\n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=openai.deployment_name,\n",
    "        messages=[{'role': 'user', 'content': prompt}],\n",
    "    ).choices[0].message[\"content\"]\n",
    "    \n",
    "    # Save the corrected text to a new file\n",
    "    with open(os.path.join(\"fragments/second_section_corrected/\", f\"{names[texts.index(text)]}_2.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
