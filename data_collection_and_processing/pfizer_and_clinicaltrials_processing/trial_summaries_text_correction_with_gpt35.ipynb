{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_BASE\"] = \"\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.api_base = os.getenv(\"OPENAI_API_BASE\") # your endpoint should look like the following https://YOUR_RESOURCE_NAME.openai.azure.com/\n",
    "openai.api_type = 'azure'\n",
    "openai.api_version = '2023-05-15' # this may change in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get texts from corrected folder, and names\n",
    "\n",
    "texts = []\n",
    "names = []\n",
    "for file in os.listdir(\"texts/med\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        with open(os.path.join(\"texts/med\", file), \"r\", encoding=\"utf-8\") as f:\n",
    "            texts.append(f.read())\n",
    "            name = file[:-4]\n",
    "            # name_1 = name.split('.')[0]\n",
    "            # name_2 = name.split('.')[1].split('_')[1]\n",
    "            # name = name_1 + '_' + name_2\n",
    "            names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output folder\n",
    "output_folder = \"clean_texts/med\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in texts:\n",
    "    if text == \"\" or len(text.split()) < 20:\n",
    "        print(names[texts.index(text)], \"is empty or too short\")\n",
    "        continue\n",
    "    text_name = names[texts.index(text)]\n",
    "    page = text_name.split('_')[-1].split('page')[0]\n",
    "    prompt = f\"\"\"The following text in triple backticks is the page number {page} of a medical text. This text could have some words separated, misspelled words, typos or strange characters, or wrong uppercase words, fix this without modify any sentence or paragraph. Keep the following in mind:\n",
    "    1. Don't put de triple backticks in the answer or any other character or extra text. Just give fixed text.\n",
    "    2. If you find something that could be the number of the page, delete it.\n",
    "    3. If you can organize something, like tables or information, do it.\n",
    "    4. Delete text as copyright, for example: \"Certara USA, Inc. 2020. All rights reserved\".\n",
    "    5. The vignettes should be \"-\".\n",
    "    6. Delete sponsor contact information.\n",
    "    7. If you find tables, charts, figures, delete them.\n",
    "    8. Delete \"Clinical Trial Results\" titles and similar.\n",
    "    Text: ```{text}```\n",
    "    Remember just fix the text and organize information without adding or deleting any sentence or paragraph. Just delete figures, tables and similar. Just save paragraphs, sentences and lists.\n",
    "    \"\"\"\n",
    "    response = openai.ChatCompletion.create(\n",
    "            engine=\"gpt-35-turbo-rfmanrique\",\n",
    "            messages=[{'role': 'user', 'content': prompt}],\n",
    "            ).choices[0].message[\"content\"]\n",
    "    \n",
    "    # Save the response in \"sections_corrected\" folder\n",
    "    with open(os.path.join(output_folder, text_name + \".txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Define the folder path where the .txt files are located\n",
    "folder_path = \"clean_texts_sections\"\n",
    "\n",
    "# List all .txt files in the folder\n",
    "txt_files = [file for file in os.listdir(folder_path) if file.endswith(\".txt\")]\n",
    "\n",
    "# Iterate through the .txt files and convert them to .json\n",
    "for txt_file in txt_files:\n",
    "    # Construct the full file paths\n",
    "    txt_file_path = os.path.join(folder_path, txt_file)\n",
    "    json_file_path = os.path.join(folder_path, txt_file.replace(\".txt\", \".json\"))\n",
    "\n",
    "    # Read the content from the .txt file\n",
    "    with open(txt_file_path, \"r\", encoding=\"utf-8\") as txt_file:\n",
    "        content = txt_file.read()\n",
    "\n",
    "    # Write the content to a new .json file\n",
    "    with open(json_file_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "        # Since the content is already in JSON format, there's no need to parse it\n",
    "        json_file.write(content)\n",
    "\n",
    "    print(f\"Converted {txt_file} to {json_file_path}\")\n",
    "\n",
    "print(\"Conversion complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each jso, get sections from clean_texts_sections folder and save them in a dict\n",
    "sections = {}\n",
    "for file in os.listdir(\"clean_texts_sections\"):\n",
    "    if file.endswith(\".json\"):\n",
    "        with open(os.path.join(\"clean_texts_sections\", file), \"r\", encoding=\"utf-8\") as f:\n",
    "            sections[file[:-5]] = json.load(f)[\"sections\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'1000-MT_MED_9011_sections'[:-9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts[names.index('1000-MT_MED_9011_sections')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text_name in sections.keys():\n",
    "    i = 0\n",
    "    for section in sections[text_name]:\n",
    "        text_name = text_name.split('.')[0]\n",
    "        page = text_name.split('_')[-1].split('page')[0]\n",
    "        prompt = f\"\"\"The following text in triple backticks is the page number {page} of a medical text. This text could have some words separated, misspelled words, typos or strange characters, or wrong uppercase words, fix this without modify any sentence or paragraph. Keep the following in mind:\n",
    "        1. Don't put de triple backticks in the answer or any other character or extra text. Just give fixed text.\n",
    "        2. If you find something that could be the number of the page, delete it.\n",
    "        3. If you can organize something, like tables or information, do it.\n",
    "        4. Delete text as copyright, for example: \"United States, NCT02949128 | Protocol, ALXN1210-aHUS-311 Â© Certara USA, Inc. 2020. All rights reserved\"\n",
    "        Text: ```{text}```\n",
    "        Remember just fix the text.\n",
    "        \"\"\"\n",
    "\n",
    "        response = openai.ChatCompletion.create(\n",
    "                engine=\"gpt-35-turbo-16k-rfmanrique\",\n",
    "                messages=[{'role': 'user', 'content': prompt}],\n",
    "                ).choices[0].message[\"content\"]\n",
    "        \n",
    "        with open(os.path.join(\"clean_texts\", f\"{names[texts.index(text)]}_sections_{i}.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(response)\n",
    "        i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
