# LLMs Testing

This folder contains resources and scripts for testing the performance of Large Language Models (LLMs) like GPT-4 and GPT-3.5 in generating plain language summaries (PLS). The evaluation includes comparing the generated texts with ground truth texts using various metrics.

## Folder Structure

- `Cochrane/`: Contains the resources and scripts related to the Cochrane dataset.
- `PPLS/`: Contains the resources and scripts related to another dataset used for generating PPLS.

### Cochrane

This folder focuses on generating and evaluating plain language summaries (PLS) using the Cochrane dataset. It includes the ground truth texts, the generated texts, and a notebook for evaluation.

- `ground_truth/`: Contains the original ground truth texts.
- `output_gpt4/`: Contains the PLS generated by GPT-4.
- `output_gpt35/`: Contains the PLS generated by GPT-3.5.
- `hypothesis_test_for_texts_generated.ipynb`: Notebook for conducting hypothesis tests on the generated texts.
- `texts_generated_with_LLMs_evaluation_with_BERTScore.ipynb`: Notebook for evaluating the generated texts using BERTScore.
- `texts_generator_with_LLMs.ipynb`: Notebook for generating texts using GPT-3.5 and GPT-4.

### PPLS

This folder is similar to the Cochrane folder but uses a different dataset. It aims to evaluate the generated texts by professionals in Health Literacy.

- `ground_truth/`: Contains the original ground truth texts.
- `output_gpt4/`: Contains the PPLS generated by GPT-4.
- `output_gpt35/`: Contains the PPLS generated by GPT-3.5.
- `Clinical Trials_Test_Dataset.xlsx`: The dataset containing clinical trial texts used as input for generating PPLS.
- `texts_generator_PPLS_with_LLMs_and_evaluation.ipynb.ipynb`: Notebook for evaluating the generated PPLS using BERTScore.
- `more_evaluations.ipynb.ipynb`: Notebook for evaluating the generated PPLS using other metrics not included in the final document.

